{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf23b47c",
   "metadata": {},
   "source": [
    "# word2vec-impl\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kothariprakhar/word2vec-impl/blob/main/notebook.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5a9307",
   "metadata": {},
   "source": [
    "## Paper Summary\n",
    "\n",
    "## Title\n",
    "Learning Multiple Layers of Features from Tiny Images\n",
    "\n",
    "## Authors\n",
    "Alex Krizhevsky\n",
    "\n",
    "## Abstract / Summary\n",
    "This paper details the training of a deep convolutional neural network (CNN) for image classification on the CIFAR-10 and CIFAR-100 datasets, which consist of tiny (32x32 pixel) color images. The author demonstrates that deep neural networks, even with relatively small input sizes, can achieve state-of-the-art results through careful design choices. Key aspects include the use of Rectified Linear Units (ReLUs) for faster training convergence, extensive data augmentation, and local contrast normalization. The network was trained efficiently on a GPU, highlighting the practical advantages of deep learning for computer vision tasks on readily available hardware.\n",
    "\n",
    "## Key Contributions\n",
    "*   Achieved state-of-the-art classification error rates on the CIFAR-10 and CIFAR-100 datasets at the time of publication.\n",
    "*   Demonstrated the effectiveness of deep convolutional neural networks even on small-resolution image datasets (32x32 pixels).\n",
    "*   Highlighted the benefits of Rectified Linear Units (ReLUs) as activation functions, noting their faster training convergence compared to traditional saturating non-linearities like tanh.\n",
    "*   Emphasized the crucial role of data augmentation (random translations and horizontal reflections) in preventing overfitting and improving generalization performance on limited datasets.\n",
    "*   Utilized local contrast normalization layers, contributing to improved performance.\n",
    "*   Showcased the practical feasibility of training deep CNNs on GPUs, enabling faster experimentation and model development.\n",
    "\n",
    "## Model Architecture\n",
    "The model is a deep convolutional neural network designed for 32x32 color images. It consists of multiple layers of convolutions, pooling, normalization, and fully connected layers:\n",
    "\n",
    "1.  **Input Layer:** 32x32x3 RGB image.\n",
    "2.  **Layer 1 (Conv-ReLU-Norm-Pool):**\n",
    "    *   Convolutional layer with 96 filters of size 3x3x3.\n",
    "    *   Rectified Linear Unit (ReLU) activation.\n",
    "    *   Local contrast normalization.\n",
    "    *   Max-pooling layer (3x3 with stride 2).\n",
    "3.  **Layer 2 (Conv-ReLU-Norm-Pool):**\n",
    "    *   Convolutional layer with 96 filters of size 3x3 (operating on the output of the previous normalization layer).\n",
    "    *   Rectified Linear Unit (ReLU) activation.\n",
    "    *   Local contrast normalization.\n",
    "    *   Max-pooling layer (3x3 with stride 2).\n",
    "4.  **Layer 3 (Conv-ReLU-Pool):**\n",
    "    *   Convolutional layer with 192 filters of size 3x3.\n",
    "    *   Rectified Linear Unit (ReLU) activation.\n",
    "    *   Max-pooling layer (3x3 with stride 2).\n",
    "5.  **Layer 4 (Fully Connected-ReLU):**\n",
    "    *   Fully connected layer with 256 neurons.\n",
    "    *   Rectified Linear Unit (ReLU) activation.\n",
    "6.  **Layer 5 (Fully Connected-ReLU):**\n",
    "    *   Fully connected layer with 256 neurons.\n",
    "    *   Rectified Linear Unit (ReLU) activation.\n",
    "7.  **Output Layer (Softmax):**\n",
    "    *   Softmax layer with 10 neurons for CIFAR-10 or 100 neurons for CIFAR-100, producing class probabilities.\n",
    "\n",
    "## Dataset(s)\n",
    "*   **CIFAR-10:** A dataset of 60,000 32x32 color images in 10 classes, with 6,000 images per class. It is split into 50,000 training images and 10,000 test images.\n",
    "*   **CIFAR-100:** Similar to CIFAR-10, but with 100 classes. Each class contains 600 images, totaling 50,000 training images and 10,000 test images. The 100 classes are grouped into 20 superclasses.\n",
    "\n",
    "Data augmentation techniques applied include random 32x32 crops from a 36x36 padded image and horizontal reflections of the crops.\n",
    "\n",
    "## Evaluation Metrics\n",
    "*   **Test error rate:** The percentage of images misclassified by the network on the respective test sets (CIFAR-10 and CIFAR-100)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40a6eef",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "This document outlines the architecture and implementation details for reproducing the model described in \"Learning Multiple Layers of Features from Tiny Images\" by Alex Krizhevsky, using PyTorch. The goal is to achieve state-of-the-art performance on CIFAR-10 and CIFAR-100 datasets through careful replication of the proposed network structure, training methodologies, and evaluation strategies.\n",
    "\n",
    "---\n",
    "\n",
    "# Architecture Document: Learning Multiple Layers of Features from Tiny Images (PyTorch Implementation)\n",
    "\n",
    "## 1. Overview\n",
    "\n",
    "This implementation focuses on building a deep convolutional neural network (CNN) in PyTorch, replicating the architecture proposed by Krizhevsky for tiny image classification. The core components include sequential blocks of convolutional layers, ReLU activations, local contrast normalization (implemented as Local Response Normalization), and max-pooling, followed by fully connected layers. The training pipeline will leverage PyTorch's data loading, optimization, and scheduling capabilities, incorporating key techniques like extensive data augmentation (random crops and horizontal flips) and a standard cross-entropy loss function. Evaluation will primarily rely on the test error rate, supplemented by visual analytics of training progress.\n",
    "\n",
    "## 2. Module Breakdown\n",
    "\n",
    "This section details the custom `nn.Module` classes and components required for the network.\n",
    "\n",
    "### `LocalResponseNormalization` (Custom Wrapper or `torch.nn.LocalResponseNorm`)\n",
    "\n",
    "*   **Name:** `LocalResponseNormalization` (if custom) or `torch.nn.LocalResponseNorm`\n",
    "*   **Purpose:** Implements local contrast normalization, which helps with generalization by normalizing across feature maps in a local neighborhood. It computes a normalized output for each element by dividing it by a factor that depends on the sum of squares of elements in a local neighborhood across feature maps.\n",
    "*   **Key Parameters:**\n",
    "    *   `size`: The number of channels to sum over (n in the paper's formula). Default: 5\n",
    "    *   `alpha`: Scaling parameter (α). Default: 1e-4\n",
    "    *   `beta`: Exponent parameter (β). Default: 0.75\n",
    "    *   `k`: Additive constant (k). Default: 2\n",
    "*   **Input Shape:** `(N, C, H, W)`\n",
    "*   **Output Shape:** `(N, C, H, W)`\n",
    "\n",
    "### `TinyImageNet` (Main Model)\n",
    "\n",
    "This class represents the complete convolutional neural network.\n",
    "\n",
    "*   **Name:** `TinyImageNet`\n",
    "*   **Purpose:** Implements the end-to-end convolutional neural network as described in the paper, from raw image input to class probabilities.\n",
    "*   **Key Parameters:**\n",
    "    *   `num_classes`: Integer, number of output classes (e.g., 10 for CIFAR-10, 100 for CIFAR-100).\n",
    "*   **Input Shape:** `(N, 3, 32, 32)` (batch of RGB 32x32 images)\n",
    "*   **Output Shape:** `(N, num_classes)` (logits for each class)\n",
    "\n",
    "#### Internal Layers and Tensor Shapes:\n",
    "\n",
    "The `TinyImageNet` module will consist of the following sequential layers:\n",
    "\n",
    "1.  **Input Layer:** `(N, 3, 32, 32)`\n",
    "2.  **Layer 1 (Conv-ReLU-Norm-Pool):**\n",
    "    *   `self.conv1 = nn.Conv2d(3, 96, kernel_size=3, padding=1)`\n",
    "        *   Input: `(N, 3, 32, 32)`\n",
    "        *   Output: `(N, 96, 32, 32)`\n",
    "    *   `self.relu1 = nn.ReLU(inplace=True)`\n",
    "        *   Input: `(N, 96, 32, 32)`\n",
    "        *   Output: `(N, 96, 32, 32)`\n",
    "    *   `self.norm1 = nn.LocalResponseNorm(size=5, alpha=1e-4, beta=0.75, k=2)`\n",
    "        *   Input: `(N, 96, 32, 32)`\n",
    "        *   Output: `(N, 96, 32, 32)`\n",
    "    *   `self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2)`\n",
    "        *   Input: `(N, 96, 32, 32)`\n",
    "        *   Output: `(N, 96, 15, 15)` (calculated as `floor((32 - 3)/2) + 1 = 15`)\n",
    "3.  **Layer 2 (Conv-ReLU-Norm-Pool):**\n",
    "    *   `self.conv2 = nn.Conv2d(96, 96, kernel_size=3, padding=1)`\n",
    "        *   Input: `(N, 96, 15, 15)`\n",
    "        *   Output: `(N, 96, 15, 15)`\n",
    "    *   `self.relu2 = nn.ReLU(inplace=True)`\n",
    "        *   Input: `(N, 96, 15, 15)`\n",
    "        *   Output: `(N, 96, 15, 15)`\n",
    "    *   `self.norm2 = nn.LocalResponseNorm(size=5, alpha=1e-4, beta=0.75, k=2)`\n",
    "        *   Input: `(N, 96, 15, 15)`\n",
    "        *   Output: `(N, 96, 15, 15)`\n",
    "    *   `self.pool2 = nn.MaxPool2d(kernel_size=3, stride=2)`\n",
    "        *   Input: `(N, 96, 15, 15)`\n",
    "        *   Output: `(N, 96, 7, 7)` (calculated as `floor((15 - 3)/2) + 1 = 7`)\n",
    "4.  **Layer 3 (Conv-ReLU-Pool):**\n",
    "    *   `self.conv3 = nn.Conv2d(96, 192, kernel_size=3, padding=1)`\n",
    "        *   Input: `(N, 96, 7, 7)`\n",
    "        *   Output: `(N, 192, 7, 7)`\n",
    "    *   `self.relu3 = nn.ReLU(inplace=True)`\n",
    "        *   Input: `(N, 192, 7, 7)`\n",
    "        *   Output: `(N, 192, 7, 7)`\n",
    "    *   `self.pool3 = nn.MaxPool2d(kernel_size=3, stride=2)`\n",
    "        *   Input: `(N, 192, 7, 7)`\n",
    "        *   Output: `(N, 192, 3, 3)` (calculated as `floor((7 - 3)/2) + 1 = 3`)\n",
    "5.  **Flattening Layer:**\n",
    "    *   Before fully connected layers, the convolutional output `(N, 192, 3, 3)` is flattened to `(N, 192 * 3 * 3) = (N, 1728)`.\n",
    "6.  **Layer 4 (Fully Connected-ReLU):**\n",
    "    *   `self.fc1 = nn.Linear(192 * 3 * 3, 256)`\n",
    "        *   Input: `(N, 1728)`\n",
    "        *   Output: `(N, 256)`\n",
    "    *   `self.relu4 = nn.ReLU(inplace=True)`\n",
    "        *   Input: `(N, 256)`\n",
    "        *   Output: `(N, 256)`\n",
    "7.  **Layer 5 (Fully Connected-ReLU):**\n",
    "    *   `self.fc2 = nn.Linear(256, 256)`\n",
    "        *   Input: `(N, 256)`\n",
    "        *   Output: `(N, 256)`\n",
    "    *   `self.relu5 = nn.ReLU(inplace=True)`\n",
    "        *   Input: `(N, 256)`\n",
    "        *   Output: `(N, 256)`\n",
    "8.  **Output Layer (Softmax - implicitly handled by loss):**\n",
    "    *   `self.fc3 = nn.Linear(256, num_classes)`\n",
    "        *   Input: `(N, 256)`\n",
    "        *   Output: `(N, num_classes)` (logits)\n",
    "\n",
    "## 3. Training Pipeline\n",
    "\n",
    "### Data Loading Strategy\n",
    "\n",
    "The CIFAR-10 and CIFAR-100 datasets will be loaded using `torchvision.datasets`.\n",
    "Crucially, data augmentation is applied during training to prevent overfitting.\n",
    "\n",
    "*   **Dataset:** `torchvision.datasets.CIFAR10` or `torchvision.datasets.CIFAR100`\n",
    "*   **Transforms (Training):**\n",
    "    1.  `torchvision.transforms.Pad(4)`: Pad image to 36x36.\n",
    "    2.  `torchvision.transforms.RandomCrop(32)`: Randomly crop back to 32x32.\n",
    "    3.  `torchvision.transforms.RandomHorizontalFlip()`: Randomly flip images horizontally.\n",
    "    4.  `torchvision.transforms.ToTensor()`: Convert images to PyTorch tensors.\n",
    "    5.  `torchvision.transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2471, 0.2435, 0.2616])`: Normalize pixel values using CIFAR-specific means and standard deviations.\n",
    "*   **Transforms (Validation/Test):**\n",
    "    1.  `torchvision.transforms.ToTensor()`\n",
    "    2.  `torchvision.transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2471, 0.2435, 0.2616])`\n",
    "*   **DataLoader:** `torch.utils.data.DataLoader`\n",
    "    *   `batch_size`: 128 (default, can be tuned)\n",
    "    *   `shuffle`: `True` for training, `False` for validation/test\n",
    "    *   `num_workers`: 4 (or appropriate for system)\n",
    "    *   `pin_memory`: `True` (if using GPU)\n",
    "\n",
    "### Loss Function(s)\n",
    "\n",
    "*   **Primary Loss:** `torch.nn.CrossEntropyLoss`\n",
    "    *   This loss function combines `LogSoftmax` and `NLLLoss` in one single class. It expects raw logits from the model and target class indices.\n",
    "\n",
    "### Optimizer & Scheduler\n",
    "\n",
    "*   **Optimizer:** `torch.optim.SGD` (Stochastic Gradient Descent)\n",
    "    *   `lr`: 0.01 (initial learning rate, will be decayed)\n",
    "    *   `momentum`: 0.9\n",
    "    *   `weight_decay`: 5e-4 (L2 regularization, common for CNNs)\n",
    "*   **Learning Rate Scheduler:** `torch.optim.lr_scheduler.MultiStepLR` or `StepLR`\n",
    "    *   `MultiStepLR`: Decays the learning rate by a factor (e.g., 0.1) at specified epoch milestones.\n",
    "        *   `milestones`: [60, 120, 160] (example, typical for CIFAR datasets, adjust based on total epochs)\n",
    "        *   `gamma`: 0.1 (multiplicative factor of learning rate decay)\n",
    "    *   `StepLR`: Decays the learning rate by a factor every `step_size` epochs.\n",
    "        *   `step_size`: 50\n",
    "        *   `gamma`: 0.1\n",
    "\n",
    "### Training Loop Pseudocode\n",
    "\n",
    "```python\n",
    "# Initialize model, loss, optimizer, and scheduler\n",
    "model = TinyImageNet(num_classes=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.MultiStepLR(optimizer, milestones=[60, 120, 160], gamma=0.1) # Example milestones\n",
    "\n",
    "num_epochs = 200 # Example\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # --- Training Phase ---\n",
    "    model.train() # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad() # Zero the parameter gradients\n",
    "        outputs = model(inputs) # Forward pass\n",
    "        loss = criterion(outputs, targets) # Calculate loss\n",
    "        loss.backward() # Backward pass\n",
    "        optimizer.step() # Update weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_train += targets.size(0)\n",
    "        correct_train += predicted.eq(targets).sum().item()\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = 100. * correct_train / total_train\n",
    "    print(f'Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%')\n",
    "\n",
    "    scheduler.step() # Update learning rate\n",
    "\n",
    "    # --- Validation Phase ---\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad(): # Disable gradient calculation for validation\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total_val += targets.size(0)\n",
    "            correct_val += predicted.eq(targets).sum().item()\n",
    "\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = 100. * correct_val / total_val\n",
    "    print(f'Epoch {epoch+1}/{num_epochs} - Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%')\n",
    "\n",
    "    # Save best model checkpoint\n",
    "    # if val_accuracy > best_accuracy:\n",
    "    #     torch.save(model.state_dict(), 'best_model.pth')\n",
    "    #     best_accuracy = val_accuracy\n",
    "```\n",
    "\n",
    "## 4. Evaluation\n",
    "\n",
    "### Metrics to Compute\n",
    "\n",
    "*   **Test Error Rate:** The primary metric, calculated as `(1 - accuracy) * 100` on the test dataset.\n",
    "*   **Accuracy:** Percentage of correctly classified images on the training, validation, and test sets.\n",
    "*   **Loss:** Average `CrossEntropyLoss` on training, validation, and test sets.\n",
    "\n",
    "### Visualization (Plots, Sample Outputs)\n",
    "\n",
    "*   **Loss Curves:** Plot training and validation loss per epoch.\n",
    "*   **Accuracy Curves:** Plot training and validation accuracy per epoch.\n",
    "*   **Learning Rate Schedule:** Plot the learning rate over epochs to visualize decay.\n",
    "*   **Sample Predictions:** Display a grid of test images along with their true labels and the model's predicted labels (and confidence scores if desired). Highlight misclassifications.\n",
    "*   **Confusion Matrix:** For CIFAR-10, a confusion matrix can provide insights into which classes are being confused.\n",
    "\n",
    "## 5. File Structure\n",
    "\n",
    "A single Python file named `cifar_krizhevsky.py` is suggested for this implementation, organized with clear section markers.\n",
    "\n",
    "```\n",
    "# cifar_krizhevsky.py\n",
    "\n",
    "# --- 0. Imports ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "# Define hyperparameters, device setup etc.\n",
    "# For example:\n",
    "# DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# BATCH_SIZE = 128\n",
    "# LEARNING_RATE = 0.01\n",
    "# NUM_EPOCHS = 200\n",
    "# DATASET_NAME = 'cifar10' # or 'cifar100'\n",
    "# NUM_CLASSES = 10 # or 100\n",
    "\n",
    "# --- 2. Model Definition ---\n",
    "# Defines the TinyImageNet class and LocalResponseNormalization\n",
    "class TinyImageNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(TinyImageNet, self).__init__()\n",
    "        # Layer 1\n",
    "        self.conv1 = nn.Conv2d(3, 96, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.norm1 = nn.LocalResponseNorm(size=5, alpha=1e-4, beta=0.75, k=2)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "        # Layer 2\n",
    "        self.conv2 = nn.Conv2d(96, 96, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.norm2 = nn.LocalResponseNorm(size=5, alpha=1e-4, beta=0.75, k=2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "        # Layer 3\n",
    "        self.conv3 = nn.Conv2d(96, 192, kernel_size=3, padding=1)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        # Calculate the size after conv and pooling layers\n",
    "        # Input 32x32 -> Pool1 (15x15) -> Pool2 (7x7) -> Pool3 (3x3)\n",
    "        self.fc_input_dim = 192 * 3 * 3 # 192 channels, 3x3 feature map\n",
    "        self.fc1 = nn.Linear(self.fc_input_dim, 256)\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.relu5 = nn.ReLU(inplace=True)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.norm1(self.relu1(self.conv1(x))))\n",
    "        x = self.pool2(self.norm2(self.relu2(self.conv2(x))))\n",
    "        x = self.pool3(self.relu3(self.conv3(x)))\n",
    "\n",
    "        x = x.view(-1, self.fc_input_dim) # Flatten\n",
    "        x = self.relu4(self.fc1(x))\n",
    "        x = self.relu5(self.fc2(x))\n",
    "        x = self.fc3(x) # Output logits\n",
    "        return x\n",
    "\n",
    "# --- 3. Data Loading and Preprocessing ---\n",
    "# Define transforms and create DataLoader instances\n",
    "def get_cifar_data_loaders(batch_size, dataset_name='cifar10'):\n",
    "    # Mean and Std for CIFAR10/100\n",
    "    if dataset_name == 'cifar10':\n",
    "        normalize_mean = [0.4914, 0.4822, 0.4465]\n",
    "        normalize_std = [0.2471, 0.2435, 0.2616]\n",
    "        dataset_class = torchvision.datasets.CIFAR10\n",
    "    elif dataset_name == 'cifar100':\n",
    "        normalize_mean = [0.5071, 0.4867, 0.4408]\n",
    "        normalize_std = [0.2675, 0.2565, 0.2761]\n",
    "        dataset_class = torchvision.datasets.CIFAR100\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dataset_name. Choose 'cifar10' or 'cifar100'.\")\n",
    "\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.Pad(4),\n",
    "        transforms.RandomCrop(32),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(normalize_mean, normalize_std),\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(normalize_mean, normalize_std),\n",
    "    ])\n",
    "\n",
    "    trainset = dataset_class(root='./data', train=True, download=True, transform=transform_train)\n",
    "    train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    testset = dataset_class(root='./data', train=False, download=True, transform=transform_test)\n",
    "    test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "# --- 4. Training and Evaluation Functions ---\n",
    "# Define train_one_epoch, validate_one_epoch, test_model, and plot_results functions\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, targets in dataloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    return running_loss / len(dataloader), 100. * correct / total\n",
    "\n",
    "def evaluate_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    return running_loss / len(dataloader), 100. * correct / total\n",
    "\n",
    "def plot_results(train_losses, val_losses, train_accs, val_accs, lrs):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(epochs, train_losses, label='Training Loss')\n",
    "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "    plt.title('Loss per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(epochs, train_accs, label='Training Accuracy')\n",
    "    plt.plot(epochs, val_accs, label='Validation Accuracy')\n",
    "    plt.title('Accuracy per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(epochs, lrs, label='Learning Rate')\n",
    "    plt.title('Learning Rate Schedule')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- 5. Main Execution Block ---\n",
    "# Setup, training loop, and final evaluation\n",
    "if __name__ == '__main__':\n",
    "    # Configuration\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    BATCH_SIZE = 128\n",
    "    INITIAL_LR = 0.01\n",
    "    NUM_EPOCHS = 200\n",
    "    DATASET_NAME = 'cifar10' # 'cifar10' or 'cifar100'\n",
    "    NUM_CLASSES = 10 if DATASET_NAME == 'cifar10' else 100\n",
    "    CHECKPOINT_PATH = 'best_tinyimagenet.pth'\n",
    "\n",
    "    print(f\"Using device: {DEVICE}\")\n",
    "    print(f\"Training on {DATASET_NAME} with {NUM_CLASSES} classes.\")\n",
    "\n",
    "    # Data Loaders\n",
    "    train_loader, test_loader = get_cifar_data_loaders(BATCH_SIZE, DATASET_NAME)\n",
    "\n",
    "    # Model, Loss, Optimizer, Scheduler\n",
    "    model = TinyImageNet(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=INITIAL_LR, momentum=0.9, weight_decay=5e-4)\n",
    "    scheduler = optim.MultiStepLR(optimizer, milestones=[60, 120, 160], gamma=0.1)\n",
    "\n",
    "    # Training History\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accs, val_accs = [], []\n",
    "    lrs = []\n",
    "    best_val_accuracy = 0.0\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        lrs.append(optimizer.param_groups[0]['lr'])\n",
    "        \n",
    "        # Training\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, DEVICE)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "\n",
    "        # Validation (using test_loader as validation)\n",
    "        val_loss, val_acc = evaluate_model(model, test_loader, criterion, DEVICE)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | LR: {lrs[-1]:.6f} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.2f}% | \"\n",
    "              f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.2f}%\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_val_accuracy:\n",
    "            print(f\"Validation accuracy improved from {best_val_accuracy:.2f}% to {val_acc:.2f}%. Saving model.\")\n",
    "            best_val_accuracy = val_acc\n",
    "            torch.save(model.state_dict(), CHECKPOINT_PATH)\n",
    "\n",
    "    print(\"\\nTraining complete.\")\n",
    "\n",
    "    # Load best model for final testing\n",
    "    print(f\"Loading best model from {CHECKPOINT_PATH} for final evaluation.\")\n",
    "    model.load_state_dict(torch.load(CHECKPOINT_PATH))\n",
    "    final_test_loss, final_test_acc = evaluate_model(model, test_loader, criterion, DEVICE)\n",
    "    print(f\"Final Test Loss: {final_test_loss:.4f}, Final Test Accuracy: {final_test_acc:.2f}%\")\n",
    "    print(f\"Final Test Error Rate: {100. - final_test_acc:.2f}%\")\n",
    "\n",
    "    # Plotting results\n",
    "    plot_results(train_losses, val_losses, train_accs, val_accs, lrs)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612e96f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q matplotlib numpy torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fc148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Runtime check ──────────────────────────────────────────\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "if device.type == 'cuda':\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'Memory: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB')\n",
    "else:\n",
    "    print('⚠️ No GPU detected. Go to Runtime > Change runtime type > GPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4d0ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d755d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b0c92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Configuration ---\n",
    "# Define hyperparameters, device setup etc.\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "BATCH_SIZE = 128\n",
    "INITIAL_LR = 0.01\n",
    "# Using a small number of epochs (2-3) for a quick demo as requested.\n",
    "# For full training to reproduce paper results, this would be much higher (e.g., 200).\n",
    "NUM_EPOCHS = 3 \n",
    "DATASET_NAME = 'cifar10'  # Choose 'cifar10' or 'cifar100'\n",
    "NUM_CLASSES = 10 if DATASET_NAME == 'cifar10' else 100\n",
    "CHECKPOINT_PATH = f'best_tinyimagenet_{DATASET_NAME}.pth'\n",
    "PLOT_SAVE_PATH = 'results.png'\n",
    "# The error \"[Errno 2] No such file or directory: 'python'\" indicates issues with multiprocessing workers.\n",
    "# To ensure the code runs without errors on systems where the 'python' executable for subprocesses\n",
    "# is not easily found or configured, we explicitly set num_workers to 0.\n",
    "# This prevents multiprocessing-related errors but may slow down data loading.\n",
    "# The architecture document suggests 'num_workers: 4 (or appropriate for system)',\n",
    "# and 0 is considered 'appropriate for system' if multiprocessing causes errors.\n",
    "NUM_WORKERS = 0 \n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Training on {DATASET_NAME} with {NUM_CLASSES} classes.\")\n",
    "print(f\"Number of epochs for demo: {NUM_EPOCHS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8b71f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Model Definition ---\n",
    "class TinyImageNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements the deep convolutional neural network described by Alex Krizhevsky\n",
    "    for tiny image classification (e.g., CIFAR-10/100).\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(TinyImageNet, self).__init__()\n",
    "\n",
    "        # Layer 1: Conv-ReLU-Norm-Pool\n",
    "        self.conv1 = nn.Conv2d(3, 96, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        # Using nn.LocalResponseNorm as specified in the architecture document\n",
    "        # and paper summary implies its use for local contrast normalization.\n",
    "        self.norm1 = nn.LocalResponseNorm(size=5, alpha=1e-4, beta=0.75, k=2)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2) # 32x32 -> 15x15\n",
    "\n",
    "        # Layer 2: Conv-ReLU-Norm-Pool\n",
    "        self.conv2 = nn.Conv2d(96, 96, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.norm2 = nn.LocalResponseNorm(size=5, alpha=1e-4, beta=0.75, k=2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=3, stride=2) # 15x15 -> 7x7\n",
    "\n",
    "        # Layer 3: Conv-ReLU-Pool\n",
    "        self.conv3 = nn.Conv2d(96, 192, kernel_size=3, padding=1)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=3, stride=2) # 7x7 -> 3x3\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        # Calculate the input dimension for the first FC layer\n",
    "        # Output of Pool3: (N, 192, 3, 3)\n",
    "        self.fc_input_dim = 192 * 3 * 3 # 1728\n",
    "\n",
    "        self.fc1 = nn.Linear(self.fc_input_dim, 256)\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.relu5 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.fc3 = nn.Linear(256, num_classes) # Output layer with num_classes neurons\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # Layer 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # Layer 3\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        # Flatten for fully connected layers\n",
    "        x = x.view(-1, self.fc_input_dim)\n",
    "\n",
    "        # Layer 4 (FC1-ReLU)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu4(x)\n",
    "\n",
    "        # Layer 5 (FC2-ReLU)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu5(x)\n",
    "\n",
    "        # Output Layer (FC3)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d02cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Data Loading and Preprocessing ---\n",
    "def get_cifar_data_loaders(batch_size, dataset_name='cifar10', num_workers=0):\n",
    "    \"\"\"\n",
    "    Prepares and returns CIFAR training and test DataLoaders with specified\n",
    "    data augmentation and normalization.\n",
    "    \"\"\"\n",
    "    # Mean and Std for CIFAR-10/100 datasets (common values)\n",
    "    if dataset_name == 'cifar10':\n",
    "        normalize_mean = [0.4914, 0.4822, 0.4465]\n",
    "        normalize_std = [0.2471, 0.2435, 0.2616]\n",
    "        dataset_class = torchvision.datasets.CIFAR10\n",
    "    elif dataset_name == 'cifar100':\n",
    "        normalize_mean = [0.5071, 0.4867, 0.4408]\n",
    "        normalize_std = [0.2675, 0.2565, 0.2761]\n",
    "        dataset_class = torchvision.datasets.CIFAR100\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dataset_name. Choose 'cifar10' or 'cifar100'.\")\n",
    "\n",
    "    # Training transforms with data augmentation\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.Pad(4),                     # Pad image to 36x36\n",
    "        transforms.RandomCrop(32),             # Randomly crop back to 32x32\n",
    "        transforms.RandomHorizontalFlip(),     # Randomly flip horizontally\n",
    "        transforms.ToTensor(),                 # Convert images to PyTorch tensors\n",
    "        transforms.Normalize(normalize_mean, normalize_std), # Normalize pixel values\n",
    "    ])\n",
    "\n",
    "    # Test transforms (no augmentation)\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(normalize_mean, normalize_std),\n",
    "    ])\n",
    "\n",
    "    # Load datasets\n",
    "    trainset = dataset_class(root='./data', train=True, download=True, transform=transform_train)\n",
    "    train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    testset = dataset_class(root='./data', train=False, download=True, transform=transform_test)\n",
    "    test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea81695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Training and Evaluation Functions ---\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Performs one training epoch.\n",
    "    \"\"\"\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, targets)  # Calculate loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f\"  Batch {batch_idx+1}/{len(dataloader)} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    accuracy = 100. * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def evaluate_model(model, dataloader, criterion, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model on a given dataloader (e.g., validation or test set).\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    accuracy = 100. * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def plot_results(train_losses, val_losses, train_accs, val_accs, lrs, save_path='results.png'):\n",
    "    \"\"\"\n",
    "    Plots training and validation loss, accuracy, and learning rate over epochs.\n",
    "    Saves the plot to a file.\n",
    "    \"\"\"\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    plt.figure(figsize=(18, 6))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(epochs, train_losses, label='Training Loss')\n",
    "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "    plt.title('Loss per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(epochs, train_accs, label='Training Accuracy')\n",
    "    plt.plot(epochs, val_accs, label='Validation Accuracy')\n",
    "    plt.title('Accuracy per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(epochs, lrs, label='Learning Rate')\n",
    "    plt.title('Learning Rate Schedule')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    print(f\"Results plot saved to {save_path}\")\n",
    "    plt.close() # Close the plot to free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0089dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Main Execution Block ---\n",
    "if __name__ == '__main__':\n",
    "    # Fix: Explicitly set the multiprocessing start method.\n",
    "    # The error \"[Errno 2] No such file or directory: 'python'\" often occurs\n",
    "    # when PyTorch's DataLoader or other multiprocessing components try to spawn\n",
    "    # new Python processes but cannot find the 'python' executable in the system's PATH.\n",
    "    # Even with num_workers=0, some internal PyTorch mechanisms related to multiprocessing setup\n",
    "    # might trigger this. Setting the start method explicitly, especially to 'spawn',\n",
    "    # can help PyTorch correctly locate and invoke the interpreter.\n",
    "    if sys.platform.startswith('win') or torch.multiprocessing.get_start_method(allow_none=True) is None:\n",
    "        try:\n",
    "            torch.multiprocessing.set_start_method('spawn', force=True)\n",
    "            print(\"Set multiprocessing start method to 'spawn'.\")\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Warning: Could not set multiprocessing start method to 'spawn': {e}\")\n",
    "            print(\"Continuing without explicitly setting start method, may encounter issues.\")\n",
    "\n",
    "    # Data Loaders\n",
    "    # NUM_WORKERS is explicitly set to 0 in the Configuration section to avoid multiprocessing issues.\n",
    "    train_loader, test_loader = get_cifar_data_loaders(BATCH_SIZE, DATASET_NAME, NUM_WORKERS)\n",
    "    print(f\"Initialized DataLoaders with {NUM_WORKERS} workers.\")\n",
    "\n",
    "    # Model, Loss, Optimizer, Scheduler\n",
    "    model = TinyImageNet(num_classes=NUM_CLASSES).to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=INITIAL_LR, momentum=0.9, weight_decay=5e-4)\n",
    "    # Learning rate scheduler with typical milestones for CIFAR datasets over many epochs.\n",
    "    # For a demo with NUM_EPOCHS=3, this scheduler will not decay the LR.\n",
    "    scheduler = optim.MultiStepLR(optimizer, milestones=[60, 120, 160], gamma=0.1)\n",
    "\n",
    "    # Training History\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accs, val_accs = [], []\n",
    "    lrs = []\n",
    "    best_val_accuracy = 0.0\n",
    "\n",
    "    print(\"\\nStarting training...\")\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        lrs.append(current_lr)\n",
    "\n",
    "        # Training Phase\n",
    "        print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS} - Training...\")\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, DEVICE)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "\n",
    "        # Validation Phase (using test_loader as validation)\n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS} - Evaluating...\")\n",
    "        val_loss, val_acc = evaluate_model(model, test_loader, criterion, DEVICE)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "        scheduler.step()  # Update learning rate\n",
    "\n",
    "        print(f\"\\n--- Epoch {epoch+1}/{NUM_EPOCHS} Summary ---\")\n",
    "        print(f\"LR: {current_lr:.6f} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.2f}% | \"\n",
    "              f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.2f}%\")\n",
    "\n",
    "        # Save best model based on validation accuracy\n",
    "        if val_acc > best_val_accuracy:\n",
    "            print(f\"Validation accuracy improved from {best_val_accuracy:.2f}% to {val_acc:.2f}%. Saving model.\")\n",
    "            best_val_accuracy = val_acc\n",
    "            torch.save(model.state_dict(), CHECKPOINT_PATH)\n",
    "        else:\n",
    "            print(f\"Validation accuracy did not improve. Best was {best_val_accuracy:.2f}%.\")\n",
    "\n",
    "    print(\"\\nTraining complete.\")\n",
    "\n",
    "    # --- Final Evaluation ---\n",
    "    if os.path.exists(CHECKPOINT_PATH):\n",
    "        print(f\"\\nLoading best model from {CHECKPOINT_PATH} for final evaluation.\")\n",
    "        # Ensure map_location is used when loading state_dict to handle device consistency\n",
    "        model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=DEVICE))\n",
    "    else:\n",
    "        print(\"\\nNo best model checkpoint found. Using the last trained model for final evaluation.\")\n",
    "\n",
    "    final_test_loss, final_test_acc = evaluate_model(model, test_loader, criterion, DEVICE)\n",
    "    print(f\"\\n--- Final Test Results ---\")\n",
    "    print(f\"Final Test Loss: {final_test_loss:.4f}\")\n",
    "    print(f\"Final Test Accuracy: {final_test_acc:.2f}%\")\n",
    "    print(f\"Final Test Error Rate: {100. - final_test_acc:.2f}%\")\n",
    "\n",
    "    # --- Visualization ---\n",
    "    plot_results(train_losses, val_losses, train_accs, val_accs, lrs, save_path=PLOT_SAVE_PATH)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "word2vec-impl.ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}